# 关于清理策略的讨论

我：
> 由于 harbor 服务的稳定性问题在整个 CI/CD 环节中越来越重要，故近期将会针对 staging 和 prod 环境中的老旧或废弃的镜像进行一些“大扫除“操作，清理规则如下：
>
> - 针对 tag ：保留 60 天内创建的所有 tag ，在 60 天之前创建的 tag ，额外保留 10 个；
> - 针对 repo ：暂时不做删除 repo 的处理（不太好确定 repo 是否还在使用，理论上讲每个 repo 下至少应该有一个 tag 是被需要的；若打算删除，则建议 repo 负责人自行进行删除操作）；
> - 私有仓库暂时不做处理；


路人甲：

> 对于那种标签数只有 1 的，是不是可以处理为不清理？

我：

> 这个我会注意一下（其实上面的处理原则是可以覆盖到这个情况的）

路人乙：

> 能否保留最后一次更新的 tag ？有些 image 比较稳定，没什么变动，有可能超过 60 天都没有修改，但是却一直在使用；

我：

> - 这个需求算是比较特殊的，因为很多 repo 有保留多个 tags 版本的需要（以便回退），所以，如果你的目标需求是仅保留最后一个 tag ，那我建议你可以在 push 前，先触发一次删除操作；
> - “有些 image 比较稳定没什么变动, 有可能超过 60 天没有修改, 但是却一直在使用”，这个需求可以根据策略进行保留，目前的策略是额外保留 10 个，满足你的要求；


我:

> 针对一些超级变态的 300+ tags 的 repo ，例如每天都能创建 5+ tags 的 repo（60 天就有 300+ 了），我会单独进行特殊处理；如果觉得自己负责的 repo 有 tags 保留策略方面的问题，请及时和我沟通……

路人丙：

> images 是存在 S3 上面的么？tag 太多导致 index 太慢？

我：

> - 目前 images 是保存在 S3 上的；
> - 针对 tags 太多的问题，怀疑有些 API 操作是基于 Harbor API 进行的遍历，可能导致执行时间随 tags 数量线性增长（在 Harbor v1.2.2 版本上 60+ tags 在 web UI 上首次展开在 7~12 秒左右），所以没用的 tags 都应该进行清理；
> - Best Practice 应该是每个 project 或 repo 的负责人自行负责 tags 的清理，但目前还是由我统一先处理吧；

路人丙：

> 有策略可以清除 60 天之内没有被 pull ，而且 images 数量在 5 个以上的么？比如写个 crontab 脚本之类的；

我：

> 首先，“而且 images 数量在 5 个以上的么”应该是 tag 数量；

路人丁：

> 我也觉得看 pull 比较好吧，有些旧的 image 还是有用的；

路人丙：

> 说错了，是 tags 数量；

我：

> 目前的清理策略是针对 tags 的呀~，所以你们说的都是满足的；

路人丙：

> 那我的意思是，可以自动清理，不让 project 负责人来搞么？

我：

> - @路人丁 目前针对 tags 的处理策略（见上面）就等价于不会完全删除掉 image ；
> - @路人丙 目前写了 [moooofly/harbor-go-client](https://github.com/moooofly/harbor-go-client) 项目用于处理这个问题（因为官方尚不支持这个功能）；
> - 针对“比如写个 crontab 脚本之类的”，目前我觉得不太需要定时执行，目前我可以每隔 15 天跑一次分析，然后再执行清除操作，可以不需要相关人员操心；
> - 相关人员可以针对处理策略提建议：比如 “针对 tag ：保留 60 天内创建的所有 tag ，在 60 之前创建的 tag ，额外保留 10 个；” 这个策略是否合适；

路人戊：

> 合适的，我觉得；

路人丙：

> 我的建议是:
>
> - 保留 60 天内的 tags ；
> - 60 天之外的看 pull 的数量，关注 60 天之外是不是被 pull 过；
> - 如果没有被 pull 过，则只保留最新 5 个 tag ；
> - 每个 image 有 5 ~10 个 tag 应该足够了
> - 如果有服务用到了比较旧的 tag, 而且长时间没有升级，比如半年升级一次的服务，可以负责人在下次跑 CI 或者用到目标 tag 时候自己升级;


我：

> - harbor 主要概念的关系：1 个 project -> 每个 project 下具有 N 种不同的 repos > 每个 repo 下具有 M 个 tags
> - project 有创建时间，但这个对我们的处理策略来说没有用处；
> - repo 有创建时间和 pull 时间，该 pull 时间对应 repo 下任意一个 tag ，最新一次，被拉取的那个时间
> - tag 有创建时间，但没有针对 tag 的 pull 时间（harbor 中定义的数据结构中不支持）；
>
> 因此
>
> - “保留 60 天内的 tag”，这个根据 tag 的创建时间可以做到（已经实现）；
> - “60 天之外的看 pull 的数量，关注 60 天之外是不是被 pull 过”，由于 pull 数量是针对 repo 整体的，无法对应到具体的 tag ，即在 API 层面无法方便的知道哪些 tag 最近被 pull 过（当然如果一定要做，就只能沟通分析 log 来搞，性价比不高），所以，只能根据 tag 创建时间的先后，“武断”的认为，后创建的 tag 应该是用户最想保留的；
> - “如果没有被 pull 过，则只保留最新 5 个 tag”，根据上一条的说明，某个 tag 是否被 pull 过是无法知道的，但目前可以做到根据 tag 的创建时间进行保留（满足保留最新 N 个需求）；

我：

> 昨天又跑了一次 tags 分析；目前在“保留 60 天内 tags + 超过 60 天外额外保留 10 个“条件下，仍然含有较多 tags 的 repo 如下
>
> - algorithm-rls/aaa | tags_count: 134
> - algorithm-rls/bbb | tags_count: 135
> - algorithm-rls/ccc | tags_count: 74
> - algorithm-rls/ddd | tags_count: 98
>
> 这里仅给出了具有 60+ 以上 tags 的 repo ；
>
> 这次分析的结果尚没有覆盖完全，且仅针对 staging 环境中的 harbor ；后续会每隔 15 天进行一次清理，针对 tags 创建过多的 repo ，希望相关负责人员私下找我确认一下，否则后续将统一针对 tags 过多的 repo 进行专项处理；

我：

> 由于 Harbor API 层面的实现问题（[#5165](https://github.com/vmware/harbor/issues/5165)），目前针对同时具有 xxx 和 xxx-rls 命名规则的 projects ，仅处理了 xxx-rls 这部分，下周会对 xxx 部分进行专项整治，请相关人员私下联系我；


